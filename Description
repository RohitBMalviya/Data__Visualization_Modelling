Data Loading, Storage and File Formats 
Problem Statement: Analyzing Sales Data from Multiple File Formats 
Dataset: Sales data in multiple file formats (e.g., CSV, Excel, JSON) 
Description: The goal is to load and analyze sales data from different file formats, including 
CSV, Excel, and JSON, and perform data cleaning, transformation, and analysis on the 
dataset. 
Tasks to Perform: 
 Obtain sales data files in various formats, such as CSV, Excel, and JSON. 
1. Load the sales data from each file format into the appropriate data structures or 
dataframes. 
2. Explore the structure and content of the loaded data, identifying any inconsistencies, 
missing values, or data quality issues. 
3. Perform data cleaning operations, such as handling missing values, removing duplicates, or correcting inconsistencies. 
4. Convert the data into a unified format, such as a common dataframe or data structure, 
to enable seamless analysis. 
5. Perform data transformation tasks, such as merging multiple datasets, splitting 
columns, or deriving new variables. 
6. Analyze the sales data by performing descriptive statistics, aggregating data by 
specific variables, or calculating metrics such as total sales, average order value, or 
product category distribution. 
7. Create visualizations, such as bar plots, pie charts, or box plots, to represent the sales 
data and gain insights into sales trends, customer behavior, or product performance. 
 
Data Cleaning and Preparation
Problem Statement: Analyzing Customer Churn in a Telecommunications Company 
Dataset: "Telecom_Customer_Churn.csv" 
Description: The dataset contains information about customers of a telecommunications 
company and whether they have churned (i.e., discontinued their services). The dataset 
includes various attributes of the customers, such as their demographics, usage patterns, and 
account information. The goal is to perform data cleaning and preparation to gain insights 
into the factors that contribute to customer churn. 
Tasks to Perform: 
1. Import the "Telecom_Customer_Churn.csv" dataset. 
2.  Explore the dataset to understand its structure and content. 
3.  Handle missing values in the dataset, deciding on an appropriate strategy. 
4. Remove any duplicate records from the dataset. 
5.  Check for inconsistent data, such as inconsistent formatting or spelling variations, 
and standardize it. 
6.  Convert columns to the correct data types as needed. 
7. Identify and handle outliers in the data. 
8. Perform feature engineering, creating new features that may be relevant to 
predicting customer churn. 
9.  Normalize or scale the data if necessary. 
10. Split the dataset into training and testing sets for further analysis. 
11. Export the cleaned dataset for future analysis or modeling.

Data Wrangling 
Problem Statement: Data Wrangling on Real Estate Market 
Dataset: "RealEstate_Prices.csv" 
Description: The dataset contains information about housing prices in a specific real estate 
market. It includes various attributes such as property characteristics, location, sale prices, 
and other relevant features. The goal is to perform data wrangling to gain insights into the 
factors influencing housing prices and prepare the dataset for further analysis or modeling. 
Tasks to Perform: 
1.  Import the "RealEstate_Prices.csv" dataset. Clean column names by removing spaces, 
special characters, or renaming them for clarity. 
2. Handle missing values in the dataset, deciding on an appropriate strategy (e.g., 
imputation or removal). 
3. Perform data merging if additional datasets with relevant information are available 
(e.g., neighborhood demographics or nearby amenities). 
4. Filter and subset the data based on specific criteria, such as a particular time period, 
property type, or location. 
5. Handle categorical variables by encoding them appropriately (e.g., one-hot encoding 
or label encoding) for further analysis. 
6.  Aggregate the data to calculate summary statistics or derived metrics such as average 
sale prices by neighborhood or property type. 
7. Identify and handle outliers or extreme values in the data that may affect the analysis 
or modeling process. 
11 Data Visualization using matplotlib 
Problem Statement: Analyzing Air Quality Index (AQI) Trends in a City  
Dataset: "City_Air_Quality.csv" 
Description: The dataset contains information about air quality measurements in a specific 
city over a period of time. It includes attributes such as date, time, pollutant levels (e.g., 
PM2.5, PM10, CO), and the Air Quality Index (AQI) values. The goal is to use the matplotlib 
library to create visualizations that effectively represent the AQI trends and patterns for 
different pollutants in the city.  
Tasks to Perform:  
1.  Import the "City_Air_Quality.csv" dataset. 
2.  Explore the dataset to understand its structure and content. 
3. Identify the relevant variables for visualizing AQI trends, such as date, pollutant 
levels, and AQI values. 
4. Create line plots or time series plots to visualize the overall AQI trend over time. 
5. Plot individual pollutant levels (e.g., PM2.5, PM10, CO) on separate line plots to 
visualize their trends over time. 
6. Use bar plots or stacked bar plots to compare the AQI values across different dates or 
time periods. 
7. Create box plots or violin plots to analyze the distribution of AQI values for different 
pollutant categories. 
8. Use scatter plots or bubble charts to explore the relationship between AQI values and 
pollutant levels. 
9. Customize the visualizations by adding labels, titles, legends, and appropriate color 
schemes.


Data Aggregation 
Problem Statement: Analyzing Sales Performance by Region in a Retail Company 
Dataset: "Retail_Sales_Data.csv" 
Description: The dataset contains information about sales transactions in a retail company. It 
includes attributes such as transaction date, product category, quantity sold, and sales 
amount. The goal is to perform data aggregation to analyze the sales performance by region 
and identify the top-performing regions. 
Tasks to Perform: 
1. Import the "Retail_Sales_Data.csv" dataset. 
2. Explore the dataset to understand its structure and content. 
3. Identify the relevant variables for aggregating sales data, such as region, sales 
amount, and product category. 
4. Group the sales data by region and calculate the total sales amount for each region. 
5. Create bar plots or pie charts to visualize the sales distribution by region. 
6. Identify the top-performing regions based on the highest sales amount. 
7. Group the sales data by region and product category to calculate the total sales 
amount for each combination. 
8. Create stacked bar plots or grouped bar plots to compare the sales amounts across 
different regions and product categories. 



Time Series Data Analysis 
Problem statement: Analysis and Visualization of Stock Market Data 
Dataset: "Stock_Prices.csv" 
Description: The dataset contains historical stock price data for a particular company over a 
period of time. It includes attributes such as date, closing price, volume, and other relevant 
features. The goal is to perform time series data analysis on the stock price data to identify 
trends, patterns, and potential predictors, as well as build models to forecast future stock 
prices. 
Tasks to Perform: 
1. Import the "Stock_Prices.csv" dataset. 
2. Explore the dataset to understand its structure and content. 
3. Ensure that the date column is in the appropriate format (e.g., datetime) for time series 
analysis. 
4. Plot line charts or time series plots to visualize the historical stock price trends over 
time. 
5. Calculate and plot moving averages or rolling averages to identify the underlying 
trends and smooth out noise. 
6. Perform seasonality analysis to identify periodic patterns in the stock prices, such as 
weekly, monthly, or yearly fluctuations. 
7. Analyze and plot the correlation between the stock prices and other variables, such as 
trading volume or market indices. 
8. Use autoregressive integrated moving average (ARIMA) models or exponential 
smoothing models to forecast future stock prices. 
